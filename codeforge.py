# -*- coding: utf-8 -*-
"""codeforge.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QDwUHdkCJUGiEBj7nFiCDNMcCkznhe-N
"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder,OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import Pipeline
from sklearn.cluster import KMeans
from sklearn.metrics import mean_squared_error,r2_score
from sklearn.compose import ColumnTransformer
import numpy as np
import matplotlib.pyplot as plt



df=pd.read_csv(r'C:\Users\Admin\Desktop\CODEATHON\marketing_campaign.csv',sep='\t')

df.head()

l=['Year_Birth','NumDealsPurchases','ID','MntSweetProducts','Dt_Customer','Complain','Z_CostContact','Z_Revenue','MntGoldProds','NumWebPurchases','NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth','AcceptedCmp1','AcceptedCmp2','AcceptedCmp3','AcceptedCmp4','AcceptedCmp5','Response']
for i in l:
  df.drop(i,axis=1,inplace=True)

df.head()

for i in df.columns:
  print(i,df[i].unique())

df.describe()

df.info()

label=LabelEncoder()
df=df.dropna()
df1=df.loc[:,['Education','Marital_Status','Income','Kidhome','Teenhome','MntWines','MntFruits','MntMeatProducts','MntFishProducts']]
df2=df.loc[:,'Recency']
text_cols = df1.select_dtypes(include=['object']).columns.tolist()
num_cols = df1.select_dtypes(exclude=['object']).columns.tolist()

df1.head()

# Define transformers for numerical and categorical features

scaler=StandardScaler()
df1['Education']=label.fit_transform(df1['Education'])
df1['Marital_Status']=label.fit_transform(df1['Marital_Status'])
'''
df1['Income']=scaler.fit_transform(df1[['Income']])
df1['MntWines']=scaler.fit_transform(df1[['MntWines']])
df1['MntFruits']=scaler.fit_transform(df1[['MntFruits']])
df1['MntMeatProducts']=scaler.fit_transform(df1[['MntMeatProducts']])
df1['MntFishProducts']=scaler.fit_transform(df1[['MntFishProducts']])
'''

df1.head()

k_range = range(1, 20)
train_set, test_set = train_test_split(df1, test_size=0.2, random_state=42)

wcss = []
for k in k_range:
    kmeans = KMeans(n_clusters=k,init='k-means++' ,random_state=42,max_iter=300)  # Initialize KMeans with current k
    kmeans.fit(train_set)  # Fit KMeans to the transformed data
    wcss.append(kmeans.inertia_)  # Append WCSS to the list
print(wcss)



kmeans = KMeans(n_clusters=8,init='k-means++',random_state=42,max_iter=300)
kmeans.fit(train_set)

predictions=kmeans.predict(test_set)
test_set['Predictions']=predictions
test_set.head()

kmeans.cluster_centers_


